{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1128220d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 100\n",
    "\n",
    "random_seed = 152525\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "                        torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "                        batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                        torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "                                                     transform=torchvision.transforms.Compose([\n",
    "                                                       torchvision.transforms.ToTensor(),\n",
    "                                                       torchvision.transforms.Normalize(\n",
    "                                                         (0.1307,), (0.3081,))\n",
    "                                                     ])),\n",
    "                        batch_size=batch_size_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5,padding=2)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=3,padding=2)\n",
    "        self.conv3 = nn.Conv2d(20, 20, kernel_size=3,padding=2)\n",
    "        self.conv_drop = nn.Dropout2d(.2)\n",
    "        self.fc1 = nn.Linear(500, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv_drop(self.conv2(x)), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv_drop(self.conv3(x)), 2))\n",
    "        x = Flatten()(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x,-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = network(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        test_losses.append(test_loss)\n",
    "        print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                        100. * batch_idx / len(train_loader), loss.item()))\n",
    "        if batch_idx%(2*log_interval)==0:\n",
    "            test()\n",
    "            test_counter.append((batch_idx*batch_size_train) + ((epoch-1)*len(train_loader.dataset)))\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        train_counter.append(\n",
    "        (batch_idx*batch_size_train) + ((epoch-1)*len(train_loader.dataset)))\n",
    "#         torch.save(network.state_dict(), '/results/model.pth')\n",
    "#         torch.save(optimizer.state_dict(), '/results/optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.347402\n",
      "\n",
      "Test set: Avg. loss: 2.3053, Accuracy: 1094/10000 (10%)\n",
      "\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.268615\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.458369\n",
      "\n",
      "Test set: Avg. loss: 1.4066, Accuracy: 5435/10000 (54%)\n",
      "\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.848880\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.691409\n",
      "\n",
      "Test set: Avg. loss: 0.5381, Accuracy: 8215/10000 (82%)\n",
      "\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.299504\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.116703\n",
      "\n",
      "Test set: Avg. loss: 0.2605, Accuracy: 9183/10000 (91%)\n",
      "\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.232518\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.118454\n",
      "\n",
      "Test set: Avg. loss: 0.2142, Accuracy: 9301/10000 (93%)\n",
      "\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.196616\n",
      "\n",
      "Test set: Avg. loss: 0.1583, Accuracy: 9495/10000 (94%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.336206\n",
      "\n",
      "Test set: Avg. loss: 0.1960, Accuracy: 9407/10000 (94%)\n",
      "\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.164170\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.113932\n",
      "\n",
      "Test set: Avg. loss: 0.1331, Accuracy: 9584/10000 (95%)\n",
      "\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.218079\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.236775\n",
      "\n",
      "Test set: Avg. loss: 0.1086, Accuracy: 9676/10000 (96%)\n",
      "\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.133991\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.139487\n",
      "\n",
      "Test set: Avg. loss: 0.0916, Accuracy: 9705/10000 (97%)\n",
      "\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.186188\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.122812\n",
      "\n",
      "Test set: Avg. loss: 0.1143, Accuracy: 9630/10000 (96%)\n",
      "\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.038988\n",
      "\n",
      "Test set: Avg. loss: 0.0816, Accuracy: 9736/10000 (97%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.537992\n",
      "\n",
      "Test set: Avg. loss: 0.0949, Accuracy: 9707/10000 (97%)\n",
      "\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.072923\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.027961\n",
      "\n",
      "Test set: Avg. loss: 0.0710, Accuracy: 9776/10000 (97%)\n",
      "\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.174262\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.057148\n",
      "\n",
      "Test set: Avg. loss: 0.0814, Accuracy: 9738/10000 (97%)\n",
      "\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.059241\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.096602\n",
      "\n",
      "Test set: Avg. loss: 0.0842, Accuracy: 9714/10000 (97%)\n",
      "\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.026930\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.011103\n",
      "\n",
      "Test set: Avg. loss: 0.0685, Accuracy: 9765/10000 (97%)\n",
      "\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.058429\n",
      "\n",
      "Test set: Avg. loss: 0.0580, Accuracy: 9819/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.249216\n",
      "\n",
      "Test set: Avg. loss: 0.0919, Accuracy: 9689/10000 (96%)\n",
      "\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.106492\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.046089\n",
      "\n",
      "Test set: Avg. loss: 0.0691, Accuracy: 9777/10000 (97%)\n",
      "\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.037512\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.066687\n",
      "\n",
      "Test set: Avg. loss: 0.0585, Accuracy: 9806/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.021839\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.030434\n",
      "\n",
      "Test set: Avg. loss: 0.0562, Accuracy: 9816/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.021692\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.071431\n",
      "\n",
      "Test set: Avg. loss: 0.0554, Accuracy: 9818/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.127293\n",
      "\n",
      "Test set: Avg. loss: 0.0550, Accuracy: 9804/10000 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.926612\n",
      "\n",
      "Test set: Avg. loss: 0.0734, Accuracy: 9766/10000 (97%)\n",
      "\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.017890\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.038950\n",
      "\n",
      "Test set: Avg. loss: 0.0565, Accuracy: 9810/10000 (98%)\n",
      "\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.036726\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.083366\n",
      "\n",
      "Test set: Avg. loss: 0.0496, Accuracy: 9822/10000 (98%)\n",
      "\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.025464\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.112275\n",
      "\n",
      "Test set: Avg. loss: 0.0501, Accuracy: 9826/10000 (98%)\n",
      "\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.013423\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.145625\n",
      "\n",
      "Test set: Avg. loss: 0.0460, Accuracy: 9858/10000 (98%)\n",
      "\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.185341\n",
      "\n",
      "Test set: Avg. loss: 0.0450, Accuracy: 9844/10000 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 1.568773\n",
      "\n",
      "Test set: Avg. loss: 0.0535, Accuracy: 9813/10000 (98%)\n",
      "\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.040190\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.070240\n",
      "\n",
      "Test set: Avg. loss: 0.0493, Accuracy: 9830/10000 (98%)\n",
      "\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.077235\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.004240\n",
      "\n",
      "Test set: Avg. loss: 0.0429, Accuracy: 9860/10000 (98%)\n",
      "\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.018258\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.047472\n",
      "\n",
      "Test set: Avg. loss: 0.0461, Accuracy: 9843/10000 (98%)\n",
      "\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.011446\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.045317\n",
      "\n",
      "Test set: Avg. loss: 0.0430, Accuracy: 9852/10000 (98%)\n",
      "\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.115583\n",
      "\n",
      "Test set: Avg. loss: 0.0405, Accuracy: 9873/10000 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 1.964170\n",
      "\n",
      "Test set: Avg. loss: 0.0512, Accuracy: 9829/10000 (98%)\n",
      "\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.017399\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.008977\n",
      "\n",
      "Test set: Avg. loss: 0.0476, Accuracy: 9829/10000 (98%)\n",
      "\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.053839\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.042758\n",
      "\n",
      "Test set: Avg. loss: 0.0394, Accuracy: 9872/10000 (98%)\n",
      "\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.054127\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.037982\n",
      "\n",
      "Test set: Avg. loss: 0.0429, Accuracy: 9866/10000 (98%)\n",
      "\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.041946\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.057031\n",
      "\n",
      "Test set: Avg. loss: 0.0414, Accuracy: 9862/10000 (98%)\n",
      "\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.036414\n",
      "\n",
      "Test set: Avg. loss: 0.0386, Accuracy: 9870/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 1.428180\n",
      "\n",
      "Test set: Avg. loss: 0.0675, Accuracy: 9793/10000 (97%)\n",
      "\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.034503\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.015513\n",
      "\n",
      "Test set: Avg. loss: 0.0383, Accuracy: 9872/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.038731\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.031256\n",
      "\n",
      "Test set: Avg. loss: 0.0397, Accuracy: 9876/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.023970\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.039388\n",
      "\n",
      "Test set: Avg. loss: 0.0399, Accuracy: 9866/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.060455\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.008708\n",
      "\n",
      "Test set: Avg. loss: 0.0390, Accuracy: 9863/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.020152\n",
      "\n",
      "Test set: Avg. loss: 0.0399, Accuracy: 9873/10000 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 2.588235\n",
      "\n",
      "Test set: Avg. loss: 0.0678, Accuracy: 9775/10000 (97%)\n",
      "\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.092203\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.007488\n",
      "\n",
      "Test set: Avg. loss: 0.0353, Accuracy: 9882/10000 (98%)\n",
      "\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.006269\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.010019\n",
      "\n",
      "Test set: Avg. loss: 0.0331, Accuracy: 9888/10000 (98%)\n",
      "\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.065107\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.031013\n",
      "\n",
      "Test set: Avg. loss: 0.0351, Accuracy: 9885/10000 (98%)\n",
      "\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.008613\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.037428\n",
      "\n",
      "Test set: Avg. loss: 0.0343, Accuracy: 9882/10000 (98%)\n",
      "\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.011671\n",
      "\n",
      "Test set: Avg. loss: 0.0435, Accuracy: 9861/10000 (98%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 2.164102\n",
      "\n",
      "Test set: Avg. loss: 0.0458, Accuracy: 9836/10000 (98%)\n",
      "\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.013452\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.062697\n",
      "\n",
      "Test set: Avg. loss: 0.0378, Accuracy: 9880/10000 (98%)\n",
      "\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.033050\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.043461\n",
      "\n",
      "Test set: Avg. loss: 0.0338, Accuracy: 9888/10000 (98%)\n",
      "\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.055603\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.005584\n",
      "\n",
      "Test set: Avg. loss: 0.0326, Accuracy: 9892/10000 (98%)\n",
      "\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.088511\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.016775\n",
      "\n",
      "Test set: Avg. loss: 0.0368, Accuracy: 9874/10000 (98%)\n",
      "\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.070398\n",
      "\n",
      "Test set: Avg. loss: 0.0354, Accuracy: 9880/10000 (98%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 1.310369\n",
      "\n",
      "Test set: Avg. loss: 0.0541, Accuracy: 9804/10000 (98%)\n",
      "\n",
      "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.072566\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.011228\n",
      "\n",
      "Test set: Avg. loss: 0.0313, Accuracy: 9894/10000 (98%)\n",
      "\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.105803\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.010400\n",
      "\n",
      "Test set: Avg. loss: 0.0351, Accuracy: 9888/10000 (98%)\n",
      "\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.090624\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.007583\n",
      "\n",
      "Test set: Avg. loss: 0.0370, Accuracy: 9874/10000 (98%)\n",
      "\n",
      "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.065452\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.030075\n",
      "\n",
      "Test set: Avg. loss: 0.0332, Accuracy: 9886/10000 (98%)\n",
      "\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.009820\n",
      "\n",
      "Test set: Avg. loss: 0.0314, Accuracy: 9884/10000 (98%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 1.550624\n",
      "\n",
      "Test set: Avg. loss: 0.0432, Accuracy: 9847/10000 (98%)\n",
      "\n",
      "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 0.071447\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.014662\n",
      "\n",
      "Test set: Avg. loss: 0.0332, Accuracy: 9880/10000 (98%)\n",
      "\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.051510\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.028389\n",
      "\n",
      "Test set: Avg. loss: 0.0314, Accuracy: 9884/10000 (98%)\n",
      "\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.132368\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.060895\n",
      "\n",
      "Test set: Avg. loss: 0.0342, Accuracy: 9884/10000 (98%)\n",
      "\n",
      "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 0.018560\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.002490\n",
      "\n",
      "Test set: Avg. loss: 0.0351, Accuracy: 9880/10000 (98%)\n",
      "\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.006530\n",
      "\n",
      "Test set: Avg. loss: 0.0317, Accuracy: 9894/10000 (98%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 1.846792\n",
      "\n",
      "Test set: Avg. loss: 0.0477, Accuracy: 9824/10000 (98%)\n",
      "\n",
      "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 0.015222\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.014823\n",
      "\n",
      "Test set: Avg. loss: 0.0352, Accuracy: 9882/10000 (98%)\n",
      "\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.002736\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.004823\n",
      "\n",
      "Test set: Avg. loss: 0.0326, Accuracy: 9877/10000 (98%)\n",
      "\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.016994\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.004258\n",
      "\n",
      "Test set: Avg. loss: 0.0298, Accuracy: 9898/10000 (98%)\n",
      "\n",
      "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 0.015781\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.034504\n",
      "\n",
      "Test set: Avg. loss: 0.0285, Accuracy: 9893/10000 (98%)\n",
      "\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.055070\n",
      "\n",
      "Test set: Avg. loss: 0.0362, Accuracy: 9881/10000 (98%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 1.612329\n",
      "\n",
      "Test set: Avg. loss: 0.0383, Accuracy: 9873/10000 (98%)\n",
      "\n",
      "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.006337\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.154933\n",
      "\n",
      "Test set: Avg. loss: 0.0347, Accuracy: 9889/10000 (98%)\n",
      "\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.016536\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.028901\n",
      "\n",
      "Test set: Avg. loss: 0.0310, Accuracy: 9893/10000 (98%)\n",
      "\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.098172\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.030897\n",
      "\n",
      "Test set: Avg. loss: 0.0276, Accuracy: 9903/10000 (99%)\n",
      "\n",
      "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.012975\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.016382\n",
      "\n",
      "Test set: Avg. loss: 0.0335, Accuracy: 9895/10000 (98%)\n",
      "\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.003145\n",
      "\n",
      "Test set: Avg. loss: 0.0297, Accuracy: 9896/10000 (98%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 2.388218\n",
      "\n",
      "Test set: Avg. loss: 0.0520, Accuracy: 9828/10000 (98%)\n",
      "\n",
      "Train Epoch: 15 [6400/60000 (11%)]\tLoss: 0.060794\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.004302\n",
      "\n",
      "Test set: Avg. loss: 0.0370, Accuracy: 9880/10000 (98%)\n",
      "\n",
      "Train Epoch: 15 [19200/60000 (32%)]\tLoss: 0.037115\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.124027\n",
      "\n",
      "Test set: Avg. loss: 0.0302, Accuracy: 9893/10000 (98%)\n",
      "\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 0.027016\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.005719\n",
      "\n",
      "Test set: Avg. loss: 0.0323, Accuracy: 9887/10000 (98%)\n",
      "\n",
      "Train Epoch: 15 [44800/60000 (75%)]\tLoss: 0.054974\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.015144\n",
      "\n",
      "Test set: Avg. loss: 0.0313, Accuracy: 9891/10000 (98%)\n",
      "\n",
      "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 0.004195\n",
      "\n",
      "Test set: Avg. loss: 0.0284, Accuracy: 9898/10000 (98%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 1.581988\n",
      "\n",
      "Test set: Avg. loss: 0.0363, Accuracy: 9876/10000 (98%)\n",
      "\n",
      "Train Epoch: 16 [6400/60000 (11%)]\tLoss: 0.025393\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.070428\n",
      "\n",
      "Test set: Avg. loss: 0.0284, Accuracy: 9896/10000 (98%)\n",
      "\n",
      "Train Epoch: 16 [19200/60000 (32%)]\tLoss: 0.033337\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.003010\n",
      "\n",
      "Test set: Avg. loss: 0.0285, Accuracy: 9898/10000 (98%)\n",
      "\n",
      "Train Epoch: 16 [32000/60000 (53%)]\tLoss: 0.004597\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.018449\n",
      "\n",
      "Test set: Avg. loss: 0.0297, Accuracy: 9891/10000 (98%)\n",
      "\n",
      "Train Epoch: 16 [44800/60000 (75%)]\tLoss: 0.030064\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.020669\n",
      "\n",
      "Test set: Avg. loss: 0.0314, Accuracy: 9897/10000 (98%)\n",
      "\n",
      "Train Epoch: 16 [57600/60000 (96%)]\tLoss: 0.002344\n",
      "\n",
      "Test set: Avg. loss: 0.0291, Accuracy: 9899/10000 (98%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 1.192900\n",
      "\n",
      "Test set: Avg. loss: 0.0315, Accuracy: 9890/10000 (98%)\n",
      "\n",
      "Train Epoch: 17 [6400/60000 (11%)]\tLoss: 0.011715\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.092678\n",
      "\n",
      "Test set: Avg. loss: 0.0302, Accuracy: 9899/10000 (98%)\n",
      "\n",
      "Train Epoch: 17 [19200/60000 (32%)]\tLoss: 0.015114\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.050862\n",
      "\n",
      "Test set: Avg. loss: 0.0349, Accuracy: 9881/10000 (98%)\n",
      "\n",
      "Train Epoch: 17 [32000/60000 (53%)]\tLoss: 0.017247\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.005106\n",
      "\n",
      "Test set: Avg. loss: 0.0310, Accuracy: 9885/10000 (98%)\n",
      "\n",
      "Train Epoch: 17 [44800/60000 (75%)]\tLoss: 0.062342\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.011726\n",
      "\n",
      "Test set: Avg. loss: 0.0295, Accuracy: 9888/10000 (98%)\n",
      "\n",
      "Train Epoch: 17 [57600/60000 (96%)]\tLoss: 0.000963\n",
      "\n",
      "Test set: Avg. loss: 0.0358, Accuracy: 9877/10000 (98%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 2.005596\n",
      "\n",
      "Test set: Avg. loss: 0.0309, Accuracy: 9894/10000 (98%)\n",
      "\n",
      "Train Epoch: 18 [6400/60000 (11%)]\tLoss: 0.000663\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.003706\n",
      "\n",
      "Test set: Avg. loss: 0.0310, Accuracy: 9893/10000 (98%)\n",
      "\n",
      "Train Epoch: 18 [19200/60000 (32%)]\tLoss: 0.003994\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.008897\n",
      "\n",
      "Test set: Avg. loss: 0.0280, Accuracy: 9907/10000 (99%)\n",
      "\n",
      "Train Epoch: 18 [32000/60000 (53%)]\tLoss: 0.010280\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.017814\n",
      "\n",
      "Test set: Avg. loss: 0.0333, Accuracy: 9881/10000 (98%)\n",
      "\n",
      "Train Epoch: 18 [44800/60000 (75%)]\tLoss: 0.011923\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.012323\n",
      "\n",
      "Test set: Avg. loss: 0.0319, Accuracy: 9894/10000 (98%)\n",
      "\n",
      "Train Epoch: 18 [57600/60000 (96%)]\tLoss: 0.001893\n",
      "\n",
      "Test set: Avg. loss: 0.0286, Accuracy: 9903/10000 (99%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 1.844862\n",
      "\n",
      "Test set: Avg. loss: 0.0470, Accuracy: 9847/10000 (98%)\n",
      "\n",
      "Train Epoch: 19 [6400/60000 (11%)]\tLoss: 0.008736\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.000802\n",
      "\n",
      "Test set: Avg. loss: 0.0275, Accuracy: 9912/10000 (99%)\n",
      "\n",
      "Train Epoch: 19 [19200/60000 (32%)]\tLoss: 0.019481\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.054888\n",
      "\n",
      "Test set: Avg. loss: 0.0298, Accuracy: 9894/10000 (98%)\n",
      "\n",
      "Train Epoch: 19 [32000/60000 (53%)]\tLoss: 0.002268\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.075553\n",
      "\n",
      "Test set: Avg. loss: 0.0297, Accuracy: 9904/10000 (99%)\n",
      "\n",
      "Train Epoch: 19 [44800/60000 (75%)]\tLoss: 0.003000\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.002020\n",
      "\n",
      "Test set: Avg. loss: 0.0274, Accuracy: 9913/10000 (99%)\n",
      "\n",
      "Train Epoch: 19 [57600/60000 (96%)]\tLoss: 0.002854\n",
      "\n",
      "Test set: Avg. loss: 0.0318, Accuracy: 9891/10000 (98%)\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 1.074723\n",
      "\n",
      "Test set: Avg. loss: 0.0333, Accuracy: 9889/10000 (98%)\n",
      "\n",
      "Train Epoch: 20 [6400/60000 (11%)]\tLoss: 0.001898\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.107071\n",
      "\n",
      "Test set: Avg. loss: 0.0300, Accuracy: 9897/10000 (98%)\n",
      "\n",
      "Train Epoch: 20 [19200/60000 (32%)]\tLoss: 0.005153\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.034690\n",
      "\n",
      "Test set: Avg. loss: 0.0328, Accuracy: 9892/10000 (98%)\n",
      "\n",
      "Train Epoch: 20 [32000/60000 (53%)]\tLoss: 0.023588\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.003598\n",
      "\n",
      "Test set: Avg. loss: 0.0268, Accuracy: 9902/10000 (99%)\n",
      "\n",
      "Train Epoch: 20 [44800/60000 (75%)]\tLoss: 0.032521\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.002130\n",
      "\n",
      "Test set: Avg. loss: 0.0299, Accuracy: 9897/10000 (98%)\n",
      "\n",
      "Train Epoch: 20 [57600/60000 (96%)]\tLoss: 0.032942\n",
      "\n",
      "Test set: Avg. loss: 0.0343, Accuracy: 9890/10000 (98%)\n",
      "\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 1.866359\n",
      "\n",
      "Test set: Avg. loss: 0.1319, Accuracy: 9630/10000 (96%)\n",
      "\n",
      "Train Epoch: 21 [6400/60000 (11%)]\tLoss: 0.016929\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 0.000472\n",
      "\n",
      "Test set: Avg. loss: 0.0287, Accuracy: 9909/10000 (99%)\n",
      "\n",
      "Train Epoch: 21 [19200/60000 (32%)]\tLoss: 0.009674\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 0.012741\n",
      "\n",
      "Test set: Avg. loss: 0.0269, Accuracy: 9909/10000 (99%)\n",
      "\n",
      "Train Epoch: 21 [32000/60000 (53%)]\tLoss: 0.073136\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 0.002202\n",
      "\n",
      "Test set: Avg. loss: 0.0267, Accuracy: 9909/10000 (99%)\n",
      "\n",
      "Train Epoch: 21 [44800/60000 (75%)]\tLoss: 0.013754\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.010455\n",
      "\n",
      "Test set: Avg. loss: 0.0278, Accuracy: 9903/10000 (99%)\n",
      "\n",
      "Train Epoch: 21 [57600/60000 (96%)]\tLoss: 0.000709\n",
      "\n",
      "Test set: Avg. loss: 0.0285, Accuracy: 9905/10000 (99%)\n",
      "\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 1.579643\n",
      "\n",
      "Test set: Avg. loss: 0.0381, Accuracy: 9870/10000 (98%)\n",
      "\n",
      "Train Epoch: 22 [6400/60000 (11%)]\tLoss: 0.014274\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 0.002911\n",
      "\n",
      "Test set: Avg. loss: 0.0303, Accuracy: 9892/10000 (98%)\n",
      "\n",
      "Train Epoch: 22 [19200/60000 (32%)]\tLoss: 0.001550\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 0.040890\n",
      "\n",
      "Test set: Avg. loss: 0.0255, Accuracy: 9910/10000 (99%)\n",
      "\n",
      "Train Epoch: 22 [32000/60000 (53%)]\tLoss: 0.018982\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 0.004471\n",
      "\n",
      "Test set: Avg. loss: 0.0264, Accuracy: 9901/10000 (99%)\n",
      "\n",
      "Train Epoch: 22 [44800/60000 (75%)]\tLoss: 0.005818\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.010974\n",
      "\n",
      "Test set: Avg. loss: 0.0292, Accuracy: 9904/10000 (99%)\n",
      "\n",
      "Train Epoch: 22 [57600/60000 (96%)]\tLoss: 0.007714\n",
      "\n",
      "Test set: Avg. loss: 0.0321, Accuracy: 9887/10000 (98%)\n",
      "\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 1.260650\n",
      "\n",
      "Test set: Avg. loss: 0.0584, Accuracy: 9814/10000 (98%)\n",
      "\n",
      "Train Epoch: 23 [6400/60000 (11%)]\tLoss: 0.047503\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 0.003165\n",
      "\n",
      "Test set: Avg. loss: 0.0265, Accuracy: 9908/10000 (99%)\n",
      "\n",
      "Train Epoch: 23 [19200/60000 (32%)]\tLoss: 0.003666\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 0.022001\n",
      "\n",
      "Test set: Avg. loss: 0.0257, Accuracy: 9919/10000 (99%)\n",
      "\n",
      "Train Epoch: 23 [32000/60000 (53%)]\tLoss: 0.050132\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 0.013728\n",
      "\n",
      "Test set: Avg. loss: 0.0282, Accuracy: 9908/10000 (99%)\n",
      "\n",
      "Train Epoch: 23 [44800/60000 (75%)]\tLoss: 0.046421\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.001943\n",
      "\n",
      "Test set: Avg. loss: 0.0257, Accuracy: 9912/10000 (99%)\n",
      "\n",
      "Train Epoch: 23 [57600/60000 (96%)]\tLoss: 0.027209\n",
      "\n",
      "Test set: Avg. loss: 0.0280, Accuracy: 9907/10000 (99%)\n",
      "\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 1.685573\n",
      "\n",
      "Test set: Avg. loss: 0.0297, Accuracy: 9905/10000 (99%)\n",
      "\n",
      "Train Epoch: 24 [6400/60000 (11%)]\tLoss: 0.007796\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 0.009850\n",
      "\n",
      "Test set: Avg. loss: 0.0341, Accuracy: 9892/10000 (98%)\n",
      "\n",
      "Train Epoch: 24 [19200/60000 (32%)]\tLoss: 0.001614\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 0.001363\n",
      "\n",
      "Test set: Avg. loss: 0.0267, Accuracy: 9905/10000 (99%)\n",
      "\n",
      "Train Epoch: 24 [32000/60000 (53%)]\tLoss: 0.003065\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 0.138869\n",
      "\n",
      "Test set: Avg. loss: 0.0278, Accuracy: 9902/10000 (99%)\n",
      "\n",
      "Train Epoch: 24 [44800/60000 (75%)]\tLoss: 0.117677\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.003198\n",
      "\n",
      "Test set: Avg. loss: 0.0369, Accuracy: 9888/10000 (98%)\n",
      "\n",
      "Train Epoch: 24 [57600/60000 (96%)]\tLoss: 0.013622\n",
      "\n",
      "Test set: Avg. loss: 0.0281, Accuracy: 9903/10000 (99%)\n",
      "\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 1.524230\n",
      "\n",
      "Test set: Avg. loss: 0.0309, Accuracy: 9886/10000 (98%)\n",
      "\n",
      "Train Epoch: 25 [6400/60000 (11%)]\tLoss: 0.121155\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 0.011004\n",
      "\n",
      "Test set: Avg. loss: 0.0320, Accuracy: 9892/10000 (98%)\n",
      "\n",
      "Train Epoch: 25 [19200/60000 (32%)]\tLoss: 0.012595\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 0.000583\n",
      "\n",
      "Test set: Avg. loss: 0.0292, Accuracy: 9895/10000 (98%)\n",
      "\n",
      "Train Epoch: 25 [32000/60000 (53%)]\tLoss: 0.001244\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 0.046145\n",
      "\n",
      "Test set: Avg. loss: 0.0257, Accuracy: 9901/10000 (99%)\n",
      "\n",
      "Train Epoch: 25 [44800/60000 (75%)]\tLoss: 0.008437\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.104917\n",
      "\n",
      "Test set: Avg. loss: 0.0261, Accuracy: 9906/10000 (99%)\n",
      "\n",
      "Train Epoch: 25 [57600/60000 (96%)]\tLoss: 0.001388\n",
      "\n",
      "Test set: Avg. loss: 0.0284, Accuracy: 9910/10000 (99%)\n",
      "\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 2.822429\n",
      "\n",
      "Test set: Avg. loss: 0.0781, Accuracy: 9755/10000 (97%)\n",
      "\n",
      "Train Epoch: 26 [6400/60000 (11%)]\tLoss: 0.003481\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 0.017456\n",
      "\n",
      "Test set: Avg. loss: 0.0271, Accuracy: 9908/10000 (99%)\n",
      "\n",
      "Train Epoch: 26 [19200/60000 (32%)]\tLoss: 0.000156\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 0.003887\n",
      "\n",
      "Test set: Avg. loss: 0.0263, Accuracy: 9902/10000 (99%)\n",
      "\n",
      "Train Epoch: 26 [32000/60000 (53%)]\tLoss: 0.002038\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 0.010769\n",
      "\n",
      "Test set: Avg. loss: 0.0277, Accuracy: 9908/10000 (99%)\n",
      "\n",
      "Train Epoch: 26 [44800/60000 (75%)]\tLoss: 0.033145\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 0.002255\n",
      "\n",
      "Test set: Avg. loss: 0.0302, Accuracy: 9889/10000 (98%)\n",
      "\n",
      "Train Epoch: 26 [57600/60000 (96%)]\tLoss: 0.001642\n",
      "\n",
      "Test set: Avg. loss: 0.0333, Accuracy: 9896/10000 (98%)\n",
      "\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 2.199316\n",
      "\n",
      "Test set: Avg. loss: 0.0354, Accuracy: 9891/10000 (98%)\n",
      "\n",
      "Train Epoch: 27 [6400/60000 (11%)]\tLoss: 0.003879\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 0.001536\n",
      "\n",
      "Test set: Avg. loss: 0.0277, Accuracy: 9902/10000 (99%)\n",
      "\n",
      "Train Epoch: 27 [19200/60000 (32%)]\tLoss: 0.049604\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 0.038832\n",
      "\n",
      "Test set: Avg. loss: 0.0281, Accuracy: 9906/10000 (99%)\n",
      "\n",
      "Train Epoch: 27 [32000/60000 (53%)]\tLoss: 0.013045\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 0.009322\n",
      "\n",
      "Test set: Avg. loss: 0.0291, Accuracy: 9904/10000 (99%)\n",
      "\n",
      "Train Epoch: 27 [44800/60000 (75%)]\tLoss: 0.001090\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 0.003965\n",
      "\n",
      "Test set: Avg. loss: 0.0311, Accuracy: 9901/10000 (99%)\n",
      "\n",
      "Train Epoch: 27 [57600/60000 (96%)]\tLoss: 0.016127\n",
      "\n",
      "Test set: Avg. loss: 0.0300, Accuracy: 9905/10000 (99%)\n",
      "\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 1.934518\n",
      "\n",
      "Test set: Avg. loss: 0.0570, Accuracy: 9822/10000 (98%)\n",
      "\n",
      "Train Epoch: 28 [6400/60000 (11%)]\tLoss: 0.003320\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 0.000865\n",
      "\n",
      "Test set: Avg. loss: 0.0270, Accuracy: 9907/10000 (99%)\n",
      "\n",
      "Train Epoch: 28 [19200/60000 (32%)]\tLoss: 0.000623\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 0.000389\n",
      "\n",
      "Test set: Avg. loss: 0.0297, Accuracy: 9895/10000 (98%)\n",
      "\n",
      "Train Epoch: 28 [32000/60000 (53%)]\tLoss: 0.000987\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 0.002452\n",
      "\n",
      "Test set: Avg. loss: 0.0347, Accuracy: 9883/10000 (98%)\n",
      "\n",
      "Train Epoch: 28 [44800/60000 (75%)]\tLoss: 0.002577\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 0.004976\n",
      "\n",
      "Test set: Avg. loss: 0.0289, Accuracy: 9910/10000 (99%)\n",
      "\n",
      "Train Epoch: 28 [57600/60000 (96%)]\tLoss: 0.029494\n",
      "\n",
      "Test set: Avg. loss: 0.0295, Accuracy: 9906/10000 (99%)\n",
      "\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 1.624399\n",
      "\n",
      "Test set: Avg. loss: 0.0314, Accuracy: 9892/10000 (98%)\n",
      "\n",
      "Train Epoch: 29 [6400/60000 (11%)]\tLoss: 0.031775\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 0.011051\n",
      "\n",
      "Test set: Avg. loss: 0.0263, Accuracy: 9918/10000 (99%)\n",
      "\n",
      "Train Epoch: 29 [19200/60000 (32%)]\tLoss: 0.001311\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 0.009097\n",
      "\n",
      "Test set: Avg. loss: 0.0285, Accuracy: 9909/10000 (99%)\n",
      "\n",
      "Train Epoch: 29 [32000/60000 (53%)]\tLoss: 0.006716\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 0.002165\n",
      "\n",
      "Test set: Avg. loss: 0.0272, Accuracy: 9913/10000 (99%)\n",
      "\n",
      "Train Epoch: 29 [44800/60000 (75%)]\tLoss: 0.011821\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 0.004111\n",
      "\n",
      "Test set: Avg. loss: 0.0275, Accuracy: 9905/10000 (99%)\n",
      "\n",
      "Train Epoch: 29 [57600/60000 (96%)]\tLoss: 0.002576\n",
      "\n",
      "Test set: Avg. loss: 0.0307, Accuracy: 9895/10000 (98%)\n",
      "\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 1.955276\n",
      "\n",
      "Test set: Avg. loss: 0.0449, Accuracy: 9861/10000 (98%)\n",
      "\n",
      "Train Epoch: 30 [6400/60000 (11%)]\tLoss: 0.015082\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 0.001273\n",
      "\n",
      "Test set: Avg. loss: 0.0270, Accuracy: 9905/10000 (99%)\n",
      "\n",
      "Train Epoch: 30 [19200/60000 (32%)]\tLoss: 0.003452\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 0.000126\n",
      "\n",
      "Test set: Avg. loss: 0.0278, Accuracy: 9904/10000 (99%)\n",
      "\n",
      "Train Epoch: 30 [32000/60000 (53%)]\tLoss: 0.004614\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 0.001859\n",
      "\n",
      "Test set: Avg. loss: 0.0260, Accuracy: 9907/10000 (99%)\n",
      "\n",
      "Train Epoch: 30 [44800/60000 (75%)]\tLoss: 0.002796\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 0.001957\n",
      "\n",
      "Test set: Avg. loss: 0.0277, Accuracy: 9913/10000 (99%)\n",
      "\n",
      "Train Epoch: 30 [57600/60000 (96%)]\tLoss: 0.001431\n",
      "\n",
      "Test set: Avg. loss: 0.0307, Accuracy: 9898/10000 (98%)\n",
      "\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 1.789378\n",
      "\n",
      "Test set: Avg. loss: 0.0287, Accuracy: 9902/10000 (99%)\n",
      "\n",
      "Train Epoch: 31 [6400/60000 (11%)]\tLoss: 0.037200\n",
      "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 0.001159\n",
      "\n",
      "Test set: Avg. loss: 0.0272, Accuracy: 9911/10000 (99%)\n",
      "\n",
      "Train Epoch: 31 [19200/60000 (32%)]\tLoss: 0.005035\n",
      "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 0.015430\n",
      "\n",
      "Test set: Avg. loss: 0.0275, Accuracy: 9908/10000 (99%)\n",
      "\n",
      "Train Epoch: 31 [32000/60000 (53%)]\tLoss: 0.005800\n",
      "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 0.006279\n",
      "\n",
      "Test set: Avg. loss: 0.0279, Accuracy: 9914/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()\n",
    "    test_counter.append(epoch*len(train_loader.dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(train_counter,train_losses, color='blue')\n",
    "plt.plot(test_counter,test_losses, color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = network(example_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Prediction: {}\".format(\n",
    "    output.data.max(1, keepdim=True)[1][i].item()))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
